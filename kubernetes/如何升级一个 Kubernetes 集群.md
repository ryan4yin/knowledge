如何升级一个 Kubernetes 集群
---


## AWS EKS 的升级方法

### 方案一：原地升级

- 托管的控制面，可以一键升级，合理的升级用时在 1 小时内
  - 控制面的 API Server 应该是灰度升级，由于 DNS 缓存等原因，期间 API Server 可能会出现短时间不可用的情况
  - 只会影响到会与 API Server 交互的服务，其他服务无影响
- 不能跨版本升级，一次只能升级一个小版本，比如 1.17 => 1.18
- 为了维持最新版，如果使用原地升级的方式，就必须与官方同步更新：每三个月升级一次
- addons 可以在 EKS 面板上一键升级，也可以手动部署 yaml 配置
- 数据平面，可以通过 EKS 节点组滚动升级
  - EKS 允许数据平面落后控制面不超过两个版本，也就是说节点组的升级可以慢慢来，不着急


### 方案二：建新集群，然后在网关层切流量

什么时候我们会选择新建集群：
- 旧集群的配置不当，无法继续使用。比如 VPC 网络设计有问题、安全组混乱等
- 工具链完善，迁移到新集群的成本很低。这时更推荐建新集群做迁移，因为风险更低。

优势：
- 风险低，可以随时回退

缺点：
- 流程繁琐，涉及到整个 EKS 集群及业务服务的所有细节，投入的成本高
- 如果要简化「建新集群再切量」的方案，需要投入较多的成本。相对比原地升级更复杂。
- 可能会存在部分对实例数量要求严格的服务，比如「单例」服务，迁移有困难。


## 通用的升级流程


### 升级前的检查与测试

- 检查 Kubernetes 更新内容，确认是否存在不兼容变更

### 执行集群升级

#### 原地升级

- 升级控制面
- 升级插件：cni 插件、kube-proxy、coredns 等
- 升级节点组

#### 新建集群再切量

- 创建新集群，部署好环境
  - 注意云上权限、数据卷、configmap/secrets 等的处理
- 执行服务迁移逻辑
  - 在新集群部署服务的副本
  - 在网关层缓慢切量到新集群，并观察各项监控指标
- 迁移完成后，在一定时间内维持可随时回退到旧集群的状态。
  - 服务的部署，都保留一份 yaml 文件的备份，回退时，先将它们部署到旧集群，再执行流量缓慢切量

如果我们在集群外部有一套独立的网关，能方便地进行服务级别的切量，那新建集群这个方案感觉是很有优势的。

理想情况下，我们应该有一个服务管理平台，能够方便地进行服务级别的迁移：

- 一键将服务部署到新集群
- 自动将流量灰度到新集群，出问题自动回滚，类似 flagger，但是是跨集群的流量灰度。
- 为了提升服务迁移速度，在前期使用少量服务验证后，可以直接使用批量迁移功能，进行服务迁移。

如果有这样完善的系统，那每次迁移的成本小，而且稳定性保障也高，因为
- 粒度很细，因此影响面也小
- 随时可回退

## 参考

- [Upgrading kubeadm clusters](https://kubernetes.io/docs/tasks/administer-cluster/kubeadm/kubeadm-upgrade/)
