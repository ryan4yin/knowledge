如何升级一个 Kubernetes 集群
---


## AWS EKS 的升级方法

### 方案一：原地升级

- 托管的控制面，可以一键升级，合理的升级用时在 1 小时内
  - 控制面的 API Server 应该是灰度升级，由于 DNS 缓存等原因，期间 API Server 可能会出现短时间不可用的情况
  - 只会影响到会与 API Server 交互的服务，其他服务无影响
- 不能跨版本升级，一次只能升级一个小版本，比如 1.17 => 1.18
- 为了维持最新版，如果使用原地升级的方式，就必须与官方同步更新：每三个月升级一次
- addons 可以在 EKS 面板上一键升级，也可以手动部署 yaml 配置
- 数据平面，可以通过 EKS 节点组滚动升级
  - EKS 允许数据平面落后控制面不超过两个版本，也就是说节点组的升级可以慢慢来，不着急


### 方案二：建新集群，然后在网关层切流量

什么时候我们会选择新建集群：
- 旧集群的配置不当，无法继续使用。比如 VPC 网络设计有问题、安全组混乱等
- 工具链完善，迁移到新集群的成本很低。这时更推荐建新集群做迁移，因为风险更低。

优势：
- 风险低，可以随时回退

缺点：
- 流程繁琐，涉及到整个 EKS 集群及业务服务的所有细节，投入的成本高
- 如果要简化「建新集群再切量」的方案，需要投入较多的成本。相对比原地升级更复杂。
- 可能会存在部分对实例数量要求严格的服务，比如「单例」服务，迁移有困难。
# 通用的 Kubernetes 升级流程


### 一、升级前的检查与测试

- 检查 Kubernetes 更新内容，确认是否存在不兼容变更

### 二、执行集群升级

#### 方案一：原地升级

- 升级控制面
- 升级插件：cni 插件、kube-proxy、coredns 等
- 升级节点组

存在的风险：
- apiserver 在控制面升级期间，可能会出现短暂不可用的情况。
  - 这对 istio/ingress-controller 等需要和 apiserver 交互的服务可能会造成影响。
  - 另外 Spot 节点回收、添加，这些可能也会依赖 apiserver? 有可能也会有问题（猜的）
- 升级完成后，控制面就无法回滚了。万一出了问题，没有好的手段回退...

#### 方案二：新建集群再切量

- 创建新集群，部署好基础环境（Istio、ingress-controller、监控、metrics-server 等）
  - 注意 ServiceAccount、configmap/secrets 等的处理
  - 注意数据卷（不方便迁移）迁移
- 需要和业务方确认，EKS 上是否有运行「对实例数量要求严格的服务」，典型的有「单例服务」只能运行 1 个
  - 这类服务建议在其他所有服务都迁移完成后，再另寻时间进行迁移
- 在业务低峰期操作
- 执行升级前，需要让云服务提供商提前预热好新集群的负载均衡（如果有新建的话）
- 执行切量之前，要先扩容 istiod/ingressgateway/aws-load-balancer-controller/coredns 等基础服务，它们的 HPA 「最小实例数」需要与旧集群当前实例数一致
- 切量前，首先把每个 deployment 在旧集群的峰值实例数，设为新旧两个集群的「HPA 最小实例数」
  - 旧集群如此设置后，我们就能具有「出问题随时回退所有流量」的能力，不需要慢慢往回切流量、等待扩容
  - 新集群如此设置后，也可以更快地切流量过来
  - 避免某些对实例伸缩敏感的服务（如推荐服务，扩缩容不能太快），因为集群间切流量而大量扩缩容，导致服务抖动。

- 从旧集群同步基础的服务配置过来（Istio 配置、K8s Service 配置等）
- 执行服务迁移逻辑
  - 在新集群部署服务的副本
  - 使用脚本验证新集群所有服务的 API 可用性
  - 在网关层缓慢切量到新集群，并观察各项监控指标（先切 0.1% 预热，后续看着 CPU 及可用率监控切）
- 迁移完成后，在一定时间内维持可随时回退到旧集群的状态
  - 服务的部署，都保留一份 yaml 文件的备份，回退时，先将它们部署到旧集群，再执行流量缓慢切量

如果我们在集群外部有一套独立的网关，能方便地进行服务级别的切量，那新建集群这个方案感觉是很有优势的。

理想情况下，我们应该有一个服务管理平台，能够方便地进行服务级别的迁移：

- 一键将服务部署到新集群
- 自动将流量灰度到新集群，出问题自动回滚，类似 flagger，但是是跨集群的流量灰度。
- 为了提升服务迁移速度，在前期使用少量服务验证后，可以直接使用批量迁移功能，进行服务迁移。

如果有这样完善的系统，那每次迁移的成本小，而且稳定性保障也高，因为
- 粒度很细，因此影响面也小
- 随时可回退


## 参考

- [Upgrading kubeadm clusters](https://kubernetes.io/docs/tasks/administer-cluster/kubeadm/kubeadm-upgrade/)
