如何升级一个 Kubernetes 集群
---

最核心的理念是：对于运行重要线上服务或数据的集群，**升级方案必须包含一个 Plan B**！也就是即使升级出了问题并且无法快速修复，也能通过回滚等手段确保服务的可用性。

## AWS EKS 的升级方法

### 方案一：原地升级

> 不论你多么有经验，都不建议在任何运行重要在线服务的集群上直接做原地升级！
> 一定要有 Plan B，即使你觉得这次升级 99% 不会出问题。

优点：

1. **实施难度低**，只需要分别升级控制面、节点组以及其他相关组件即可。
2. **不需要额外的资源占用**

缺点：

1. **风险高，缺乏回滚能力**。生产环境做原地升级前一定确认好兼容性。同时一定要联系好 AWS 工程师实时的企业级支持，避免控制面升级出现问题。

其他特点：

- 托管的控制面，可以一键升级，合理的升级用时在 1 小时内
  - 控制面的 API Server 应该是灰度升级，由于 DNS 缓存等原因，期间 API Server 可能会出现短时间不可用的情况
  - 只会影响到会与 API Server 交互的服务，其他服务无影响
- 不能跨版本升级，一次只能升级一个小版本，比如 1.17 => 1.18
- 为了维持最新版，如果使用原地升级的方式，就必须与官方同步更新：每三至四个月就得升级一次
- addons 可以在 EKS 面板上一键升级，也可以手动部署 yaml 配置
- 数据平面，可以通过 EKS 节点组滚动升级
  - EKS 允许数据平面落后控制面不超过两个版本，也就是说节点组的升级可以慢慢来，不着急

建议应用场景：

- 仅建议在 Spark / Flink / Hive / Presto / ArgoWorkflow 等不对外提供服务的集群上使用原地升级。这类服务可以接受短暂的不可用。
- **不建议在对外提供服务的集群上使用原地升级**，因为升级过程中总会存在短暂不可用的风险。

### 方案二：建新集群，然后在网关层切流量

> 对任何重要的线上服务集群，都建议使用这个方案。

> 对于数据库集群等有状态服务，我没接触过不太了解，但总之集群升级必须有 Plan B.

优势：
- 风险低，可以随时回退

缺点：

- 需要额外的一份资源占用。为了确保回滚能力，升级期间需要维持两个集群的运行。
- 流程繁琐，涉及到整个 EKS 集群及业务服务的所有细节，工具链不完善的话，投入的成本高
    - 另一方面，如果对多集群的支持比较完善，那么这个方案的成本就很低了。
- 如果要简化「建新集群再切量」的方案，需要投入较多的成本。相对比原地升级更复杂。
- 可能会存在部分对实例数量要求严格的服务，比如「单例」服务，需要挨个跟业务方确认迁移策略。

建议应用场景：

- 旧集群的配置不当，无法继续使用时，那显然需要建个新集群。比如 VPC 网络设计有问题、安全组混乱等
- 集群包含在线服务，且对服务的可用性要求较高时，建议使用这个方案。因为这个方案可以随时回退，风险低。

总结一下，**这个方案是比较稳妥的方案，也是 AWS 最推荐的方案。如果可以实现一个比较自动化的、可重复的「集群创建流程」以及「服务迁移流程」，以及我觉得这个方案是非常好的。**

## 通用的 Kubernetes 升级流程


### 一、升级前的检查与测试

- 检查 Kubernetes 更新内容，确认是否存在不兼容变更
- 检查使用的其他组件如 Istio 对 Kubernetes 的支持情况，确认这些组件是否也需要升级

### 二、执行集群升级

#### 方案一：原地升级

- 升级控制面
- 升级插件：cni 插件、kube-proxy、coredns 等
- 升级节点组

存在的风险：
- apiserver 在控制面升级期间，可能会出现短暂不可用的情况。
  - 这对 istio/ingress-controller 等需要和 apiserver 交互的服务可能会造成影响。
  - 另外 Spot 节点回收、添加，这些可能也会依赖 apiserver? 有可能也会有问题（猜的）
- 升级完成后，控制面就无法回滚了。万一出了问题，没有好的手段回退...

#### 方案二：新建集群再切量

- 创建新集群，部署好基础环境（Istio、ingress-controller、监控、metrics-server 等）
  - 注意 ServiceAccount、configmap/secrets 等的处理
  - 注意数据卷（不方便迁移）迁移
- 需要和业务方确认，EKS 上是否有运行「对实例数量要求严格的服务」，典型的有「单例服务」只能运行 1 个
  - 这类服务建议在其他所有服务都迁移完成后，再另寻时间进行迁移
- 在业务低峰期操作
- 执行升级前，需要让云服务提供商提前预热好新集群的负载均衡（如果有新建的话）
- 执行切量之前，要先扩容 istiod/ingressgateway/aws-load-balancer-controller/coredns 等基础服务，它们的 HPA 「最小实例数」需要与旧集群当前实例数一致
- 切量前，首先把每个 deployment 在旧集群的峰值实例数，设为新旧两个集群的「HPA 最小实例数」
  - 旧集群如此设置后，我们就能具有「出问题随时回退所有流量」的能力，不需要慢慢往回切流量、等待扩容
  - 新集群如此设置后，也可以更快地切流量过来
  - 避免某些对实例伸缩敏感的服务（如推荐服务，扩缩容不能太快），因为集群间切流量而大量扩缩容，导致服务抖动。

- 从旧集群同步基础的服务配置过来（Istio 配置、K8s Service 配置等）
- 执行服务迁移逻辑
  - 在新集群部署服务的副本
  - 使用脚本验证新集群所有服务的 API 可用性
  - 在网关层缓慢切量到新集群，并观察各项监控指标（先切 0.1% 预热，后续看着 CPU 及可用率监控切）
- 迁移完成后，在一定时间内维持可随时回退到旧集群的状态
  - 服务的部署，都保留一份 yaml 文件的备份，回退时，先将它们部署到旧集群，再执行流量缓慢切量

如果我们在集群外部有一套独立的网关，能方便地进行服务级别的切量，那新建集群这个方案感觉是很有优势的。

理想情况下，我们应该有一个服务管理平台，能够方便地进行服务级别的迁移：

- 一键将服务部署到新集群
- 自动将流量灰度到新集群，出问题自动回滚，类似 flagger，但是是跨集群的流量灰度。
- 为了提升服务迁移速度，在前期使用少量服务验证后，可以直接使用批量迁移功能，进行服务迁移。

如果有这样完善的系统，那每次迁移的成本小，而且稳定性保障也高，因为
- 粒度很细，因此影响面也小
- 随时可回退


## 参考

- [Upgrading kubeadm clusters](https://kubernetes.io/docs/tasks/administer-cluster/kubeadm/kubeadm-upgrade/)
- [蚂蚁大规模 Kubernetes 集群无损升级实践指南【探索篇】](https://mp.weixin.qq.com/s/aB4CXC4P8F1q5LrE8mEBDg)
